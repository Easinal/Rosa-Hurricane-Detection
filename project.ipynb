{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### by Tianyang Guï¼ŒZijin Wan, Jiashun he"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import some library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confirm the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work on dataset, here we use the tf.dataset to load and proprecess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the dictionay for label\n",
    "dic={'damage':0,'no_damage':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the preprocess function when reading the data\n",
    "def preprocess(path, label):\n",
    "    # read image\n",
    "    image = tf.io.read_file(path) \n",
    "    #decode \n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    # rsize o the same input size of resnet \n",
    "    image = tf.image.resize(image, [224, 224]) \n",
    "     # normalize\n",
    "    image /= 255.0 \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the image augument function\n",
    "def image_aug(img,label):\n",
    "    #random contrast\n",
    "    #img = tf.image.random_contrast(img,lower=0.9,upper=1.8)\n",
    "    #random saturration\n",
    "    #img = tf.image.random_saturation(img,lower=0.8,upper=1.2)\n",
    "    #random flip up and down\n",
    "    img=tf.image.random_flip_up_down(img)\n",
    "    #random flip left and right\n",
    "    img=tf.image.random_flip_left_right(img)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the function to get dataset \n",
    "def get_dataset(path_trans):\n",
    "    #get the path to dataset\n",
    "    data_path_train = pathlib.Path(path_trans)\n",
    "    #get the last two level of the whole path , like damage/111.jpeg or no_damage/11111.jpeg\n",
    "    all_image_paths_train = list(data_path_train.glob('*/*')) \n",
    "    #transform all path to string, preparing for reading \n",
    "    all_image_paths_train = [str(path) for path in all_image_paths_train]\n",
    "    #get the label, damage or no_damage\n",
    "    label_names_train = sorted(item.name for item in data_path_train.glob('*/') if item.is_dir())\n",
    "    #transform damage to 0, no_damage to 1\n",
    "    all_image_labels_train = [dic[pathlib.Path(path).parent.name] for path in all_image_paths_train]\n",
    "    #get the data path and label\n",
    "    ds_train = tf.data.Dataset.from_tensor_slices((all_image_paths_train, all_image_labels_train))\n",
    "    #preprocess fuciton, transform the data path to data and other preprocess\n",
    "    ds_train=ds_train.map(preprocess)\n",
    "    return ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get validation data\n",
    "ds_validation=get_dataset('p_data/validation_another')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get training data\n",
    "ds_train=get_dataset('p_data/train_another')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do img augument on training data \n",
    "ds_train_a=ds_train.map(image_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test=get_dataset('p_data/test_another')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test_1=get_dataset('p_data/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show some data in trianing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=ds_train_a.take(4).as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas=[]\n",
    "for element in data:\n",
    "    datas.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#draw the data\n",
    "f, ax = plt.subplots(2,2)\n",
    "ax[0][0].imshow(datas[0][0], cmap='jet')\n",
    "ax[0][1].imshow(datas[1][0], cmap='jet')\n",
    "ax[1][0].imshow(datas[2][0], cmap='jet')\n",
    "ax[1][1].imshow(datas[3][0], cmap='jet')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start to build model\n",
    "#### use transfer learning, transfer ResNet50V2 and add to fully connnected layers after it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### code to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the resnet50 as base model, with maxpooling and not incldue fully connected layers\n",
    "base_model=tf.keras.applications.ResNet50V2(pooling=max,include_top=False,input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the summary of base mdoel\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here to build model after the resnet\n",
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs)\n",
    "#use the gloval average pooling\n",
    "\n",
    "x=GlobalAveragePooling2D(x)\n",
    "#use dropout\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "#add a layer with 128 nodes\n",
    "x=tf.keras.layers.Dense(128,activation='relu')(x)\n",
    "#use dropout\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "#add a layer with 64 nodes\n",
    "x=tf.keras.layers.Dense(64,activation='relu')(x)\n",
    "#the output layer,1 nodes with sigmoid function\n",
    "outputs=tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Conv2d_BN(x, nb_filter, kernel_size, strides=(1, 1), padding='same'):\n",
    "    x = tf.keras.layers.Conv2D(nb_filter, kernel_size, padding=padding, strides=strides)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x =tf.keras.layers.Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(224, 224, 3)) \n",
    "x_1= Conv2d_BN(inputs,32,1)\n",
    "\n",
    "x=Conv2d_BN(inputs,32,3)\n",
    "x=Conv2d_BN(x,32,3)\n",
    "x=tf.keras.layers.Concatenate(axis=3)([x_1, x])\n",
    "x=tf.keras.layers.MaxPooling2D()(x)\n",
    "x=Conv2d_BN(x,64,3)\n",
    "x=Conv2d_BN(x,64,3)\n",
    "\n",
    "x=tf.keras.layers.MaxPooling2D()(x)\n",
    "x=Conv2d_BN(x,128,3)\n",
    "x=Conv2d_BN(x,128,3)\n",
    "x=Conv2d_BN(x,128,3)\n",
    "x=tf.keras.layers.MaxPooling2D()(x)\n",
    "x=Conv2d_BN(x,256,3)\n",
    "x=Conv2d_BN(x,256,3)\n",
    "x=Conv2d_BN(x,256,3)\n",
    "x=tf.keras.layers.MaxPooling2D()(x)\n",
    "GlobalAveragePooling2D = tf.keras.layers.GlobalAveragePooling2D() \n",
    "x=GlobalAveragePooling2D(x)\n",
    "#use dropout\n",
    "#add a layer with 128 nodes\n",
    "x=tf.keras.layers.Dense(256)(x)\n",
    "x=tf.keras.layers.BatchNormalization()(x)\n",
    "x=tf.keras.layers.Activation('relu')(x)\n",
    "#use dropout\n",
    "#add a layer with 64 nodes\n",
    "x=tf.keras.layers.Dense(256)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x =tf.keras.layers.Activation('relu')(x)\n",
    "#the output layer,1 nodes with sigmoid function\n",
    "outputs=tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, \"mini_resnet.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.003),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=60,restore_best_weights=True)\n",
    "history = model.fit(ds_train_a.shuffle(2560).batch(16).prefetch(2),\n",
    "                    epochs=30,#the epoch should be 600 and here we only trian 30 times to save time and resource\n",
    "                    validation_data=ds_validation.batch(256).prefetch(2),\n",
    "                   callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step1: trian only the last 2 dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##here to freeze or unfreeze the layers in resnet\n",
    "for layer in base_model.layers[:]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here to freeze or unfreeze the layers in model\n",
    "for layer in model.layers[-6:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.000003),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the early stop\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=60,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### becasue we restarted the kernel and run all, it takes too long to trian 600 epochs, so here we only train 30 epochs. And the model we showed in the presentation which is completely trained has been saved. we will load it and show it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model\n",
    "history = model.fit(ds_train_a.shuffle(4).batch(32).prefetch(2),\n",
    "                    epochs=30,#the epoch should be 600 and here we only trian 30 times to save time and resource\n",
    "                    validation_data=ds_validation.batch(256).prefetch(2),\n",
    "                   callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the accuracy and loss\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss') \n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step2 :train the last 2 Conv-layers in resnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##here to freeze or unfreeze the layers in resnet\n",
    "#the last 2 conv layer\n",
    "for layer in base_model.layers[-7:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here to freeze or unfreeze the layers in model\n",
    "#freeze the dense layer\n",
    "for layer in model.layers[-6:]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the summary to confirm\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=20,restore_best_weights=True)\n",
    "history = model.fit(ds_train_a.shuffle(4).batch(32).prefetch(2),\n",
    "                    epochs=10,#the epoch should be 100 here, we set it 10 to save time\n",
    "                    validation_data=ds_validation.batch(256).prefetch(2),\n",
    "                   callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step3: train the first layer in resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##here to freeze or unfreeze the layers in resnet\n",
    "#the last 2 conv layer\n",
    "for layer in base_model.layers[-7:]:\n",
    "    layer.trainable=False\n",
    "for layer in base_model.layers[:3]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here to freeze or unfreeze the layers in model\n",
    "#freeze the dense layer\n",
    "for layer in model.layers[-6:]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=20,restore_best_weights=True)\n",
    "history = model.fit(ds_train_a.shuffle(4).batch(32).prefetch(2),\n",
    "                    epochs=10,#the epoch should be 100 here, we set it 10 to save time\n",
    "                    validation_data=ds_validation.batch(256).prefetch(2),\n",
    "                   callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to save model\n",
    "#model_s.save('v5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Because it takes too long to restart kernel and run all, so here we load a model that we trianed before , which get the best performance on test.  This model has been trained for 3 steps just like what above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#laod the saved model\n",
    "model_s=tf.keras.models.load_model('v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_s.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_s.layers[-7].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_1,a_1=model_s.evaluate(ds_test_1.batch(512))\n",
    "print(f'The accuracy on unbalanced test is {a_1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l,a=model_s.evaluate(ds_test.batch(512))\n",
    "print(f'The accuracy on balanced test is {a}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do some error analysis after we trained a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### here to find images wrongly predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index to count total number wrongly predicted\n",
    "i=0\n",
    "c=0\n",
    "#the list to save the wrongly predicted data\n",
    "wrong_data=[]\n",
    "for data in ds_test:\n",
    "    datas=np.expand_dims(data[0],axis=0)\n",
    "    predicted=np.where(model_s(datas)<0.5,0,1)\n",
    "    i+=1\n",
    "    if data[1]!=predicted:\n",
    "        wrong_data.append(data)\n",
    "        c+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### draw the grad-CAM to analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    img=wrong_data[129][0].numpy()\n",
    "    x = np.expand_dims(img, axis=0)\n",
    "    get_maps = tf.keras.models.Model(inputs = [model_s.layers[-7].inputs], outputs = [model_s.layers[-7].output,model_s.layers[-7].layers[-4].output])\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        model_out, last_conv_layer = get_maps(x)\n",
    "    \n",
    "        class_out = tf.reduce_max(model_out)\n",
    "\n",
    "    grads = tape.gradient(class_out,last_conv_layer)\n",
    "    # Here we combine all the gradients for each feature map \n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    # to multiply the pooled grads with each feature map and take the average across\n",
    "    # all the feature maps to make the heat map\n",
    "    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, last_conv_layer), axis=-1)\n",
    "    heatmap = heatmap.numpy()\n",
    "    heatmap[heatmap < 0] = 0 #relu\n",
    "    heatmap = (heatmap - heatmap.min())/(heatmap.max() - heatmap.min())\n",
    "    heatmap = heatmap.reshape((7, 7))\n",
    "\n",
    "    # We plot the (7,7) heatmap\n",
    "    plt.imshow(heatmap,cmap='jet')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_heatmap = np.uint8(cv2.resize(heatmap,(224,224))*255)\n",
    "val = np.uint8(256-resized_heatmap)\n",
    "heatmap_final = cv2.applyColorMap(val, cv2.COLORMAP_JET)\n",
    "fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "ax.imshow(img, cmap='jet')\n",
    "ax.imshow(heatmap_final, cmap='jet',alpha=0.3)\n",
    "ax.axis('off');\n",
    "fig.suptitle(f'label: {wrong_data[129][1].numpy()}',y=0.92,fontsize=14);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
